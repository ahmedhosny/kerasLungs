{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all data (train and test only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None):\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "def AUC(test_labels,test_prediction):\n",
    "    n_classes = 2\n",
    "    # http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        # ( actual labels, predicted probabilities )\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], test_prediction[:, i]) # flip here\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return round(roc_auc[0],3) , round(roc_auc[1],3)\n",
    "\n",
    "def manageDataFrames():\n",
    "    \n",
    "    trainList = [\"lung1\",\"lung2\"]  # , , , ,  ,\"oncopanel\" , \"moffitt\",\"moffittSpore\"  ,\"oncomap\" , ,\"lung3\" \n",
    "    validateList = [] # leave empty\n",
    "    testList = [\"nsclc_rt\"] # split to val and test\n",
    "\n",
    "    dataFrame = pd.DataFrame.from_csv('master_170228.csv', index_col = 0)\n",
    "    dataFrame = dataFrame [ \n",
    "        ( pd.notnull( dataFrame[\"pathToData\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"pathToMask\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"stackMin\"] ) ) &\n",
    "        ( pd.isnull( dataFrame[\"patch_failed\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"surv1yr\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"surv2yr\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"histology_grouped\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"stage\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"age\"] ) )  \n",
    "        ]\n",
    "   \n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "    \n",
    "    ###### FIX ALL\n",
    "    \n",
    "    #1# clean histology - remove smallcell and other\n",
    "    # histToInclude - only NSCLC\n",
    "    histToInclude = [1.0,2.0,3.0,4.0]\n",
    "    # not included - SCLC and other and no data [ 0,5,6,7,8,9 ]\n",
    "    dataFrame = dataFrame [ dataFrame.histology_grouped.isin(histToInclude) ]\n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "    print (\"all patients: \" , dataFrame.shape)\n",
    "    \n",
    "    #2# use all stages for now.\n",
    "        \n",
    "    ###### GET TRAINING / TESTING\n",
    "\n",
    "    dataFrameTrain = dataFrame [ dataFrame[\"dataset\"].isin(trainList) ]\n",
    "    dataFrameTrain = dataFrameTrain.reset_index(drop=True)\n",
    "    print (\" final - train patients: \" , dataFrameTrain.shape)\n",
    "    \n",
    "    dataFrameTest = dataFrame [ dataFrame[\"dataset\"].isin(testList) ]\n",
    "    dataFrameTest = dataFrameTest.reset_index(drop=True)\n",
    "    print (\" before - test patients : \" , dataFrameTest.shape)\n",
    "    \n",
    "    ###### FIX TESTING\n",
    "    \n",
    "    #3# type of treatment - use only radio or chemoRadio - use .npy file\n",
    "    \n",
    "    chemoRadio = np.load(\"rt_chemoRadio.npy\").astype(str)\n",
    "    dataFrameTest = dataFrameTest [ dataFrameTest[\"patient\"].isin(chemoRadio) ]\n",
    "   \n",
    "    #4# (rt only) use all causes of death\n",
    "    \n",
    "    print (\"final test patients: \" , dataFrameTest.shape)\n",
    "\n",
    "    return dataFrameTrain,dataFrameTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manageDataFrames():\n",
    "    trainList = [\"lung1\",\"lung2\"]  # , , , ,  ,\"oncopanel\" , \"moffitt\",\"moffittSpore\"  ,\"oncomap\" , ,\"lung3\" \n",
    "    validateList = [] # leave empty\n",
    "    testList = [\"nsclc_rt\"] # split to val and test\n",
    "\n",
    "    dataFrame = pd.DataFrame.from_csv('master_170228.csv', index_col = 0)\n",
    "    dataFrame = dataFrame [ \n",
    "        ( pd.notnull( dataFrame[\"pathToData\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"pathToMask\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"stackMin\"] ) ) &\n",
    "        ( pd.isnull( dataFrame[\"patch_failed\"] ) ) &\n",
    "        ( pd.notnull( dataFrame[\"surv1yr\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"surv2yr\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"histology_grouped\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"stage\"] ) )  &\n",
    "        ( pd.notnull( dataFrame[\"age\"] ) )  \n",
    "        ]\n",
    "   \n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "    \n",
    "    ###### FIX ALL\n",
    "    \n",
    "    #1# clean histology - remove smallcell and other\n",
    "    # histToInclude - only NSCLC\n",
    "    histToInclude = [1.0,2.0,3.0,4.0]\n",
    "    # not included - SCLC and other and no data [ 0,5,6,7,8,9 ]\n",
    "    dataFrame = dataFrame [ dataFrame.histology_grouped.isin(histToInclude) ]\n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    #2# use all stages for now.\n",
    "    stageToInclude = [1.0,2.0,3.0]\n",
    "    dataFrame = dataFrame [ dataFrame.stage.isin(stageToInclude) ]\n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "    print (\"all patients: \" , dataFrame.shape)\n",
    "\n",
    "        \n",
    "    ###### GET TRAINING / TESTING\n",
    "\n",
    "    dataFrameTrain = dataFrame [ dataFrame[\"dataset\"].isin(trainList) ]\n",
    "    dataFrameTrain = dataFrameTrain.reset_index(drop=True)\n",
    "    print (\" final - train patients: \" , dataFrameTrain.shape)\n",
    "    \n",
    "    dataFrameTest = dataFrame [ dataFrame[\"dataset\"].isin(testList) ]\n",
    "    dataFrameTest = dataFrameTest.reset_index(drop=True)\n",
    "    print (\" before - test patients : \" , dataFrameTest.shape)\n",
    "    \n",
    "    ###### FIX val/TESTING\n",
    "    \n",
    "    #3# type of treatment - use only radio or chemoRadio - use .npy file\n",
    "    \n",
    "    chemoRadio = np.load(\"rt_chemoRadio.npy\").astype(str)\n",
    "    dataFrameTest = dataFrameTest [ dataFrameTest[\"patient\"].isin(chemoRadio) ]\n",
    "   \n",
    "    #4# (rt only) use all causes of death\n",
    "        \n",
    "    #FOR VALIDATION AND TESTING.\n",
    "    # take test and split it in 30% and 70% (30% and 70% should have equal samples of 0 and 1)\n",
    "    dataFrameTest = dataFrameTest.reset_index(drop=True)\n",
    "    print (\"validate and test patients \" , dataFrameTest.shape)\n",
    "\n",
    "\n",
    "\n",
    "    ## FOR TRAINING:\n",
    "    # now we need equal samples of 0's and 1's\n",
    "    # get numbers\n",
    "    # zero = dataFrameTrain [  (dataFrameTrain['surv2yr']== 0.0)  ]\n",
    "    # print ('zeros ' , zero.shape)\n",
    "    # one = dataFrameTrain [  (dataFrameTrain['surv2yr']== 1.0)  ]\n",
    "    # print ('ones ' , one.shape)\n",
    "    # zero = zero.sample(one.shape[0],random_state=1) # RANDOM\n",
    "    # #put both together\n",
    "    # dataFrameTrain = pd.DataFrame()\n",
    "    # dataFrameTrain = dataFrameTrain.append(zero)\n",
    "    # dataFrameTrain = dataFrameTrain.append(one)\n",
    "    # dataFrameTrain = dataFrameTrain.reset_index(drop=True)\n",
    "    # print ('final train size:' , dataFrameTrain.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # take test and split it in 30% and 70% (30% and 70% should have equal samples of 0 and 1)\n",
    "    # get 30% and 70%\n",
    "    thirty = int(dataFrameTest.shape[0]*0.3)   ######################################\n",
    "    if thirty % 2 != 0:\n",
    "        thirty = thirty + 1\n",
    "    seventy = dataFrameTest.shape[0] - thirty\n",
    "\n",
    "    # get 0's and 1's.\n",
    "    zero = dataFrameTest [  (dataFrameTest['surv2yr']== 0.0)  ]\n",
    "    one = dataFrameTest [  (dataFrameTest['surv2yr']== 1.0)  ]\n",
    "\n",
    "    # split to val and test\n",
    "    half = int(thirty/2.0)\n",
    "\n",
    "    trueList = [True for i in range (half)]\n",
    "    #\n",
    "    zeroFalseList = [False for i in range (zero.shape[0] - half )]\n",
    "    zero_msk = trueList + zeroFalseList\n",
    "    random.seed(41)\n",
    "    random.shuffle(zero_msk)\n",
    "    zero_msk = np.array(zero_msk)\n",
    "    #\n",
    "    oneFalseList = [False for i in range (one.shape[0] - half )]\n",
    "    one_msk = trueList + oneFalseList\n",
    "    random.seed(41)\n",
    "    random.shuffle(one_msk)\n",
    "    one_msk = np.array(one_msk)\n",
    "\n",
    "    # VALIDATE\n",
    "    zero_val = zero[zero_msk]\n",
    "    one_val = one[one_msk]\n",
    "    dataFrameValidate = pd.DataFrame()\n",
    "    dataFrameValidate = dataFrameValidate.append(zero_val)\n",
    "    dataFrameValidate = dataFrameValidate.append(one_val)\n",
    "    dataFrameValidate = dataFrameValidate.reset_index(drop=True)\n",
    "    print ('final validate size:' , dataFrameValidate.shape)\n",
    "\n",
    "    # TEST\n",
    "    zero_test = zero[~zero_msk]\n",
    "    one_test = one[~one_msk]\n",
    "    dataFrameTest = pd.DataFrame()\n",
    "    dataFrameTest = dataFrameTest.append(zero_test)\n",
    "    dataFrameTest = dataFrameTest.append(one_test)\n",
    "    dataFrameTest = dataFrameTest.reset_index(drop=True)\n",
    "    print ('final test size:' , dataFrameTest.shape)\n",
    "\n",
    "\n",
    "    return dataFrameTrain,dataFrameValidate,dataFrameTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('all patients: ', (902, 32))\n",
      "(' final - train patients: ', (221, 32))\n",
      "(' before - test patients : ', (450, 32))\n",
      "('validate and test patients ', (293, 32))\n",
      "('final validate size:', (88, 32))\n",
      "('final test size:', (205, 32))\n"
     ]
    }
   ],
   "source": [
    "dataFrameTrain,val,dataFrameTest = manageDataFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrameTest.stage.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voxel count i.e. volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add columns for both\n",
    "# train\n",
    "voxelList = dataFrameTrain.voxelCountList.tolist()\n",
    "dataFrameTrain['volume'] =  [ int(x[1:-1].split(\",\")[0]) if \",\" in x[1:-1] else int(x[1:-1]) for x in voxelList ] \n",
    "# test\n",
    "voxelList = dataFrameTest.voxelCountList.tolist()\n",
    "dataFrameTest['volume'] =  [ int(x[1:-1].split(\",\")[0]) if \",\" in x[1:-1] else int(x[1:-1]) for x in voxelList ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240L,) (240L,)\n"
     ]
    }
   ],
   "source": [
    "# which to work on\n",
    "dataset = dataFrameTest\n",
    "\n",
    "voxelList = dataset.voxelCountList.tolist()\n",
    "voxelListClean = np.array( [ int(x[1:-1].split(\",\")[0]) if \",\" in x[1:-1] else int(x[1:-1]) for x in voxelList ] )\n",
    "y =  np.array( dataset.surv2yr.tolist() )\n",
    "# y = np.array( [ 2 if x==0 else 1 for x in dataset.surv2yr.tolist() ] )\n",
    "print voxelListClean.shape , y.shape\n",
    "# 0 didnt survive, 1 survived\n",
    "# 1 survived, 2 didnt survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53036620109790844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, voxelListClean, pos_label=0)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 4) (315L,)\n",
      "(240, 4) (240L,)\n",
      "0.526 0.526\n"
     ]
    }
   ],
   "source": [
    "# prepare training\n",
    "xTrainRF = dataFrameTrain[['stage','age','histology_grouped','volume']]\n",
    "yTrainRF = np.array( dataFrameTrain.surv2yr.tolist() , 'int64' )\n",
    "print xTrainRF.shape , yTrainRF.shape\n",
    "\n",
    "# prepare testing\n",
    "xTestRF = dataFrameTest[['stage','age','histology_grouped','volume']]\n",
    "yTestRF = np.array( dataFrameTest.surv2yr.tolist() , 'int64' )\n",
    "print xTestRF.shape , yTestRF.shape\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs= 200, criterion = 'entropy' )\n",
    "clf.fit(xTrainRF, yTrainRF)\n",
    "\n",
    "preds = clf.predict_proba( xTestRF )\n",
    "\n",
    "yTestRFCat = to_categorical(yTestRF, 2)\n",
    "auc1,auc2 = AUC(yTestRFCat,preds)\n",
    "print auc1,auc2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
